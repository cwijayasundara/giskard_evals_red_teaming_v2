{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai langchain-community pypdf faiss-cpu openai tiktoken \"giskard[llm]\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import warnings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "_ = load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "LLAMAPARSE_API_KEY = os.getenv('LLAMACLOUD_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 48 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain import FAISS, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "policy_doc_location = \"docs/pb116349-business-health-select-handbook-1024-pdfa.pdf\"\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True)\n",
    "loader = PyPDFLoader(policy_doc_location)\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How much can I claim for optical expenses?',\n",
       " 'result': 'You can claim 80% of the cost of prescribed glasses and contact lenses, up to £200 a year. Additionally, you can claim up to £25 a year for an eye test. If you have an excess, you do not have to pay it when claiming for these optical expenses.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = FAISS.from_documents(loader.load_and_split(text_splitter), OpenAIEmbeddings())\n",
    "\n",
    "# Prepare QA chain\n",
    "PROMPT_TEMPLATE = \"\"\"You are the insurence policy Assistant, a helpful AI assistant made by Giskard.\n",
    "Your task is to answer common questions on insurence policies.\n",
    "You will be given a question and relevant excerpts from the insurence policy documents.\n",
    "Please provide short and clear answers based on the provided context. Be polite and helpful.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Your answer:\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\n",
    "policy_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)\n",
    "\n",
    "# Test that everything works\n",
    "policy_qa_chain.invoke({\"query\": \"How much can I claim for optical expenses?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06 10:34:54,214 pid:2768 MainThread giskard.models.automodel INFO     Your 'prediction_function' is successfully wrapped by Giskard's 'PredictionFunctionModel' wrapper class.\n"
     ]
    }
   ],
   "source": [
    "import giskard\n",
    "import pandas as pd\n",
    "\n",
    "def model_predict(df: pd.DataFrame):\n",
    "    \"\"\"Wraps the LLM call in a simple Python function. The function takes a pandas.DataFrame containing the input variables needed\n",
    "    by your model, and must return a list of the outputs (one for each row).\n",
    "    \"\"\"\n",
    "    return [policy_qa_chain.invoke({\"query\": question}) for question in df[\"question\"]]\n",
    "\n",
    "giskard_model = giskard.Model(\n",
    "    model=model_predict,\n",
    "    model_type=\"text_generation\",\n",
    "    name=\"Insurence policy document question answering\",\n",
    "    description=\"This model answers any question about the insurence policy document\",\n",
    "    feature_names=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06 10:35:02,039 pid:2768 MainThread giskard.datasets.base INFO     Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06 10:35:02,096 pid:2768 MainThread giskard.datasets.base INFO     Casting dataframe columns from {'question': 'object'} to {'question': 'object'}\n",
      "2024-11-06 10:35:04,295 pid:2768 MainThread giskard.utils.logging_utils INFO     Predicted dataset with shape (2, 1) executed in 0:00:02.254999\n",
      "[{'query': 'Whats the cashback amount for optical expenses?', 'result': 'The cashback amount for optical expenses is 80% of the cost of prescribed glasses and contact lenses, up to £200 a year.'}\n",
      " {'query': 'Whats the cashback amount for dental expenses?', 'result': 'The cashback amount for dental expenses is 80% of your dentist’s fees, up to £400 a year.'}]\n"
     ]
    }
   ],
   "source": [
    "# Optional: let’s test that the wrapped model works\n",
    "examples = [\n",
    "    \"Whats the cashback amount for optical expenses?\",\n",
    "    \"Whats the cashback amount for dental expenses?\",\n",
    "]\n",
    "giskard_dataset = giskard.Dataset(pd.DataFrame({\"question\": examples}), target=None)\n",
    "\n",
    "print(giskard_model.predict(giskard_dataset).prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scan the model for all the vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_report = giskard.scan(giskard_model, giskard_dataset)\n",
    "display(full_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_report.to_html(\"scan_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suite = full_report.generate_test_suite(name=\"Test suite generated by scan\")\n",
    "test_suite.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
